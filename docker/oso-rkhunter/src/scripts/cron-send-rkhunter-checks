#!/bin/env python
# vim: expandtab:tabstop=4:shiftwidth=4

"""
 This script is used to check the rkhunter logs for infections and report to Zabbix.
 It will report an issue to Zabbix if any lines match 'infected' or 'Warning'.
"""

from __future__ import print_function
from datetime import datetime

import os
import re
import time
import yaml

import boto3
import botocore

# Reason: disable pylint import-error because our modules aren't loaded on jenkins.
# pylint: disable=import-error
from openshift_tools.monitoring.zagg_sender import ZaggSender


class CheckStatus(object):
    """ Class to check for issues found in rkhunter logs. """


    def __init__(self):
        self.yaml_config = None


    @staticmethod
    def check_rkhunter(log_message, logfile):
        """ Check number of occurrences of the provided string in the specified logfile. """

        total_issues = 0

        if os.path.isfile(logfile):
            with open(logfile) as open_file:
                stripped_line = list([line.rstrip() for line in open_file.readlines()])
                for line in stripped_line:
                    line_found = re.search(log_message, line, re.IGNORECASE)
                    if line_found:
                        total_issues += 1

                return total_issues
        else:
            raise ValueError(logfile + ' does not exist.')


    @staticmethod
    def upload_data(config_dict, logfile):
        """ Use the current AWS_PROFILE to upload files to the specified bucket.

        Raises:
            A ValueError if the specified bucket can not be found.
        """

        hostname = config_dict['orkhunter_host_name']
        credsfile = config_dict['orkhunter_creds_file']
        bucket = config_dict['orkhunter_s3_bucket']
        cluster = config_dict['orkhunter_cluster_name']

        os.environ["AWS_SHARED_CREDENTIALS_FILE"] = credsfile

        s3_session = boto3.resource('s3')
        exists = True

        try:
            s3_session.meta.client.head_bucket(Bucket=bucket)

        except botocore.exceptions.ClientError as client_exception:
            error_code = int(client_exception.response['Error']['Code'])

            if error_code == 404:
                exists = False

        if exists:
            s3_client = boto3.resource('s3')
            s3_bucket = s3_client.Bucket(bucket)

            if os.path.isfile(logfile):
                print('\nUploading logfile to %s bucket.' % bucket)
                with open(logfile) as open_file:
                    log_data = open_file.read()

                    bucket_path = cluster + '/' + \
                                  hostname + '/' + \
                                  datetime.utcnow().strftime('%Y') + '/' + \
                                  datetime.utcnow().strftime('%m') + '/' + \
                                  datetime.utcnow().strftime('%d') + '_status.txt'

                    s3_bucket.put_object(Key=bucket_path, Body=log_data)

            else:
                raise ValueError(logfile + ' does not exist.')

        else:
            raise ValueError(bucket + ' does not exist.')


    # pylint: disable=line-too-long
    @staticmethod
    def get_config(config_path):
        """ Open and read config data from the variables file. """

        config_settings = {}

        if os.path.isfile(config_path):
            with open(config_path, 'r') as scan_config:
                yaml_config = yaml.load(scan_config)

                if yaml_config['orkhunter_host_name']:
                    config_settings['orkhunter_host_name'] = yaml_config['orkhunter_host_name']

                if yaml_config['orkhunter_creds_file']:
                    config_settings['orkhunter_creds_file'] = yaml_config['orkhunter_creds_file']

                if yaml_config['orkhunter_s3_bucket']:
                    config_settings['orkhunter_s3_bucket'] = yaml_config['orkhunter_s3_bucket']

                if yaml_config['orkhunter_cluster_name']:
                    config_settings['orkhunter_cluster_name'] = yaml_config['orkhunter_cluster_name']

                if yaml_config['orkhunter_log_file']:
                    config_settings['orkhunter_log_file'] = yaml_config['orkhunter_log_file']

                if yaml_config['orkhunter_stamp_file']:
                    config_settings['orkhunter_stamp_file'] = yaml_config['orkhunter_stamp_file']

        return config_settings


    @staticmethod
    def check_stamp(time_stamp):
        """ Check if the timestamp is older than 1 week for the provided time_stamp file. """

        total_issues = 0

        if os.path.isfile(time_stamp):
            with open(time_stamp) as open_file:
                write_date = open_file.readline().strip()
                if int(write_date) < int(time.time()) - (7 * 24 * 60 * 60):
                    total_issues += 1

                return total_issues

        else:
            with open(time_stamp, 'w+') as open_file:
                open_file.write(str(int(time.time())))
            return total_issues


    # pylint: disable=no-member
    def main(self):
        """ Main function. """

        zag = ZaggSender()
        config_path = '/secrets/aws_config.yml'

        yaml_config = self.get_config(config_path)

        logfile = yaml_config['orkhunter_log_file']
        stampfile = yaml_config['orkhunter_stamp_file']

        checks = {
            "rkhunter.found.warning": r"\[ Warning \]",
            "rkhunter.found.infection": r"INFECTED$"
        }

        for zabbix_key, search_term in checks.iteritems():
            scan_status = self.check_rkhunter(search_term, logfile)

            if scan_status > 0:
                self.upload_data(yaml_config, logfile)

            zag.add_zabbix_keys({zabbix_key: scan_status})

        stamp_key = 'rkhunter.not.reporting'
        stamp_status = self.check_stamp(stampfile)

        zag.add_zabbix_keys({stamp_key: stamp_status})
        zag.send_metrics()


if __name__ == '__main__':
    RKHUNTER_STATUS = CheckStatus()
    RKHUNTER_STATUS.main()
